### Comparison Sorts

For each

* How it is implemented?
  * Stable?
  * Space complexity
* Best case and worst case runtimes
* Why would we use it?



###### Stability

* Two elements that are the equal are ordered the same in final result as in original list

###### Inversion

* an out of place pair



### Selection Sort

* Move minimum of unsorted to the left

###### Runtime:

1 + 2 + 3 + .. + N = **Θ(N^2)**

* Best case: Θ(N^2)

* Worst case: Θ(N^2)

###### Why use?

* Simple to code
* Minimize swapping operations -- only N swaps
* Pretty bad overall though

###### Stable?

* **No**
* Because we swap tje element

[2a 2b 1] --> [1 2b 2a] -- > [1 2b 2a]



### HeapSort:

1. Bottom up heapification to **build a maxheap**
   * bubble down everyone from the end

2. Repeat N times:
   * **removeMax** and put max at end
   * **Bubble down** to create smaller maxheap while growing sorted array from righthand side of array

###### Bottomup

**Original array** ----bottom up heapification (Θ(N)) ----> **MaxHeapArray** ----Iterative process of removeMax (placing Max at end) ----> **Sorted Array**



###### Why using maxheap?

* When we removeMax, we remove the top of the heap and put it in the end of array.
* At the same time, we need to put the last item in the heap to the front which is the position the Max should go to.
* So it is good that, we just **swap the Max and the last** and then to bubble down to create the new smaller heap, we finish our job.

###### Runtime:

1. Heapifying the array -- **Θ(N)**
2. Bubble down operation -- Θ(N log N)

* Best case: Θ(N) -- all the elements are duplicate
* Worst case: **Θ(N log N)**

###### Why use?

* Good worst case bound
* If we already are given a heap
* In-place -- constant space complexity



### Insersion Sort

* For each element, keep swapping it to the left until it's bigger than the left element
* Build sorted sublist on left side of list

###### Runtime:

* Best case: **Θ(N)** -- input list sorted ascending
* Worst case: **Θ(N^2)** -- input list sorted descending

**Θ(N + K)**

* N looking at each element
* Total swaps that we do!

###### Why use?

* Very fast on **small inputs** (n < 15)
* Very fast when the input list is **nearly sorted**



### MergeSort

* Kepp merging runs together, starting with runs of size zero / one

###### Pseudocode

```java
function mergesort(list)
	if (list is of length 0 or 1)
		return list;
	a = mergesort(left half of list)
	b = mergesort(right half of list)
	return merge(a, b)
```

###### Runtime:

* Best case: **Θ(N log N)**
* Worst case: **Θ(N log N)**

###### Why use?

* good worst case bound

* Stable -- often used with objects
* good with linked lists



### Quicksort

#### 3 Scan:

1. Choose a pivot and partition into 3 groups

* Smaller than pivot
* equal
* greater than pivot

2. Recurse on each group

#### Hoare Partitioning

1. Let first item be pivot
2. Create two points **L** and **G**
   1. L likes smaller / equal elements start at **left**
   2. G likes larger elements start at **right**
3. Move pointers, stop on disliked items
4. If both stopped, **swap** L and G and move pointers

5. Done when pointers cross, then swap G & pivot

###### Why use?

* The fastest sort
* In place with Haore
* Stable with 3-scan

###### Runtime:

* Best case: **Θ(N log N)**
* Worst case: **Θ(N^2)**

